---
title: "fastcampus_머신러닝_8"
author: "huimin"
date: '2019 7 21 '
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 기초 설정
```{r}
library(tidyverse)
library(readr)
library(e1071) # 서포트 벡터 머신
library(caret)
library(MLmetrics)
```


# 서포트 벡터 머신 알고리즘의 개요


![Caption](img/day08_1.jpg)


![Caption](img/day08_2.jpg)


# 초평면과 소프트 마진


![Caption](img/day08_3.jpg)


![Caption](img/day08_4.jpg)


![Caption](img/day08_5.jpg)


![Caption](img/day08_6.jpg)


![Caption](img/day08_7.jpg)


![Caption](img/day08_8.jpg)


![Caption](img/day08_9.jpg)


![Caption](img/day08_10.jpg)


# 서포트 벡터 머신 프로세스


![Caption](img/day08_11.jpg)


![Caption](img/day08_12.jpg)


# 서포트 벡터 머신 분류모형


![Caption](img/day08_13.jpg)


![Caption](img/day08_14.jpg)


# 서포트 벡터 머신 회귀모형


![Caption](img/day08_15.jpg)


![Caption](img/day08_16.jpg)


# 서포트 벡터 머신 분류모형 적합 실습


서포트 벡터 머신에 할당하는 데이터셋은 **데이터 표준화 처리**가 되어 있어야 한다. 그런데 **svm() 함수의 scale 인자가 자동으로 데이터 표준화를 실행**하므로, 편리하다.


목표변수가 범주형인 경우 type은 "C-classification" 으로 자동 할당된다. 분류모형의 경우 gamma와 cost를 별도로 지정해주지 않으면 기본값이 적용된다.


## 1. 기본값으로 분류모형 적합하기
```{r}
# 실습용 데이터 불러오기
load(file = "practice_data/RFC_Model.Rdata")

# 데이터 구조 다시 한 번 확인해보기
str(trainSet)

# 기본값으로 분류모형 적합해보기
# probability를 TRUE로 할 경우, 모델에 확률 예측값들이 포함된다.
fit.svm0 <- svm(formula = grade ~.,
                data = trainSet,
                probability = TRUE)


# 적합한 모형 출력하기
print(fit.svm0)

# 비용상수
fit.svm0$cost

# gamma
fit.svm0$gamma

# 서포트 벡터 확인해보기
fit.svm0$SV %>% head(n = 10)

# 서포트 벡터의 가중치 벡터 확인해보기
fit.svm0$coefs %>% head(n = 10)

# 입력변수별 가중치를 계산한다.
# %*%는 행렬의 곱셈이다.
weights <- apply(t(fit.svm0$coefs) %*% fit.svm0$SV,
                 MARGIN = 2,
                 FUN = function(x) sqrt(sum(x^2))) %>% 
  round(digits = 2) %>% 
  sort(decreasing = TRUE)

# 변수의 중요도를 출력한다.
print(weights)


# 오분류된 수를 확인한다.
sum(fit.svm0$fitted != trainSet$grade)

# 오분류율을 구한다.
100 * sum(fit.svm0$fitted != trainSet$grade) / nrow(trainSet)
```


## 2. 분류모형의 성능 평가하기
```{r}
# 확률 예측값
tr.prod <- predict(object = fit.svm0, 
                   newdata = trainSet,
                   probability = TRUE) %>% attr(which = "probabilities")

# 예측값
tr.pred <- fit.svm0$fitted

# 실제값
tr.real <- trainSet$grade

# 혼돈행렬
confusionMatrix(tr.pred, tr.real)

# F1 점수
F1_Score(tr.pred, tr.real)


# 시험셋에 적용해보기
te.pred <- predict(object = fit.svm0, newdata = testSet)
te.real <- testSet$grade

# 혼돈행렬
confusionMatrix(te.pred, te.real)

# F1 점수
F1_Score(te.pred, te.real)
```


## 3. 분류모형 튜닝 실습


**tune.svm() 함수**를 이용하여 튜닝한다. 탐색할 **gamma와 cost의 범위를 분석가가 선정**한 다음 tune.svm() 함수에 할당하면 된다. tune.svm()함수는 최적 모형일 때의 하이퍼 파라미터를 제시한다.


```{r}
# 결과를 항상 동일하게 만들기
set.seed(123)

fit.svm1 <- tune.svm(x = trainSet[, -12],
                     y = trainSet[, 12],
                     gamma = seq(from = 0, to = 3, by = 0.5),
                     cost = seq(from = 1, to = 5, by = 1))


# 베스트 하이퍼 파라미터를 확인한다.
print(fit.svm1)
fit.svm1$best.parameters$gamma
fit.svm1$best.parameters$cost


# 튜닝 결과를 2차원 그래프로 그리면, gamma와 cost의 최적값 범위를 확인할 수 있다.
# 이 범위를 이용하여 색이 진한 부분으로 범위를 좁혀 튜닝을 다시 할 수도 있다.
plot(fit.svm1)


# 베스트 모형을 적합한다.
fit.svm2 <- svm(formula = grade ~.,
                data = trainSet,
                probability = TRUE,
                gamma = fit.svm1$best.parameters$gamma,
                cost = fit.svm1$best.parameters$cost)


# 변수의 중요도를 계산하여, 객체에 저장한다.
weights <- apply(t(fit.svm2$coefs) %*% fit.svm2$SV,
                 MARGIN = 2,
                 FUN = function(x) sqrt(sum(x^2))) %>% round(digits = 2) %>% 
  sort(decreasing = TRUE)

# 변수의 중요도 출력
print(weights)


# 오분류된 수를 확인한다.
sum(fit.svm2$fitted != trainSet$grade)

# 오분류율을 계산한다.
100 * sum(fit.svm2$fitted != trainSet$grade) / nrow(trainSet)
```


## 4. 튜닝 전 후의 성능 비교


아래의 결과를 보면 알 수 있듯이, 성능이 매우 크게 향상되었다.


```{r}
# 튜닝 전 혼동행렬과 F1 점수
confusionMatrix(te.pred, te.real)
F1_Score(te.pred, te.real)


# 튜닝 후 혼동행렬과 F1 점수
te.pred <- predict(object = fit.svm2, newdata = testSet)
te.real <- testSet$grade

confusionMatrix(te.pred, te.real)
F1_Score(te.pred, te.real)
```


# 서포트 벡터 머신 회귀모형 적합 실습


목표변수가 연속형인 경우 type은 "eps-regression"으로 자동 할당된다. 회귀모형 또한, gamma와 cost 및 epsilon을 별도로 지정해주지 않으면 기본값이 적용된다.


**주의해야 할 점은 서포트 벡터 머신의 경우, 입력변수가 모두 숫자형이어야 한다.** svm() 함수에 숫자형이 아닌 컬럼이 포함되면 자동으로 데이터 표준화를 실행할 때 제외한다.


따라서 범주형 컬럼의 경우에는 이진형일 경우 -1 또는 1로 변경하고, 다항이면 각 레벨을 이진형으로 나누어 변경한다. 예를 들어, 직업 컬럼에 학생, 회사원, 주부와 같이 3개의 레벨로 되어 있다면 직업_학생, 직업_회사원, 직업_주부와 같이 3개의 변수를 생성한 다음 각각을 -1 또는 1로 인코딩하는 것이다. **(더미변수가 아니다 아무래도 0을 숫자형이라고 생각하지 않는 모양이다.)**


## 1. 데이터 전처리 하기
```{r}
# 실습용 데이터 불러오기
load(file = "practice_data/RFR_Model.Rdata")

# 데이터의 인코딩 형식 변환하기
colnames(trainSet) <- iconv(colnames(trainSet), from = "UTF-8", to = "EUC-KR")
colnames(testSet) <- iconv(colnames(testSet), from = "UTF-8", to = "EUC-KR")

# 구조 확인하기
str(trainSet)
str(testSet)

# 데이터셋에서 범주형 자료를 숫자형으로 변경해주기 (-1 과 1로)
trainSet[, 8:10] <- sapply(trainSet[, 8:10],
                           FUN = function(x) ifelse(as.numeric(x) == 1, -1, 1)) %>% 
  as.data.frame()

testSet[, 8:10] <- sapply(testSet[, 8:10],
                           FUN = function(x) ifelse(as.numeric(x) == 1, -1, 1)) %>% 
  as.data.frame()
```


## 2. 서포트 벡터 머신 회귀모형을 적합한다.
```{r}
# 기본값으로 모형 적합하기
fit.svr0 <- svm(formula = 거래금액 ~.,
                data = trainSet)


# 분류모형에서 했던 과정들은 생략하고, 바로 변수의 중요도 측정하기
weights <- apply(t(fit.svr0$coefs) %*% fit.svr0$SV,
                 MARGIN = 2,
                 FUN = function(x) sqrt(sum(x^2))) %>% round(digits = 2) %>% 
  sort(decreasing = TRUE)

print(weights)

# 회귀모형의 성능평가 지표 RMSE 측정하기
RMSE(fit.svr0$fitted, trainSet$거래금액)
```


## 3. 회귀모형 튜닝 실습
```{r}
set.seed(123)

# 최적의 파라미터 찾기
tune.svr <- tune.svm(x = trainSet[, Xvars],
                     y = trainSet[, yvar],
                     gamma = seq(from = 0, to = 3, by = 0.5),
                     cost = seq(from = 1, to = 5, by = 1),
                     epsilon = seq(from = 0, to = 1, by = 0.1))


# 최적의 파라미터
# 회귀모형의 경우 파라미터가 3가지이기 때문에, 그래프로 출력할 수 없다.
tune.svr$best.parameters$gamma
tune.svr$best.parameters$cost
tune.svr$best.parameters$epsilon


# 최적의 회귀모형 적합하기
fit.svr1 <- svm(formula = 거래금액 ~.,
                data = trainSet,
                probability = TRUE,
                gamma = tune.svr$best.parameters$gamma,
                cost = tune.svr$best.parameters$cost,
                epsilon = tune.svr$best.parameters$epsilon)


# 변수의 중요도
weights <- apply(t(fit.svr1$coefs) %*% fit.svr1$SV,
                 MARGIN = 2,
                 FUN = function(x) sqrt(sum(x^2))) %>% round(digits = 2) %>% 
  sort(decreasing = TRUE)

print(weights)
```


## 4. 튜닝 전 후 RMSE값 비교해보기


아래의 결과를 보면 알 수 있듯이, 성능이 매우 크게 개선되었다.


```{r}
# 튜닝 전
RMSE(fit.svr0$fitted, trainSet$거래금액)

# 튜닝 후
RMSE(fit.svr1$fitted, trainSet$거래금액)

```