---
title: "fastcampus_머신러닝_4"
author: "huimin"
date: "2019년 5월 30일"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 기초설정
```{r}
library(tidyverse)
library(readr)
library(caret)
library(e1071)
library(MLmetrics)
library(pROC)
```


# 로지스틱 회귀분석 알고리즘 개요


- 로지스틱 회귀분석은 목표변수가 연속형 자료인 선형 회귀분석과 달리 **목표변수가 범주형 자료일 때 사용하는 알고리즘**이다.
- 모형이 적합되면 각 입력변수들이 목표변수에 영향을 미치는 정도를 알 수 있다. 즉, **해석하기 쉬운 모형이므로 의사결정나무 알고리즘과 함께 분류모형 적합에 가장 많이 사용된다.**
- 0~1의 값을 갖는 추정확률을 반환한다. 분석가가 **기준점(cut-off)를 정해 목표변수를 여러 레벨로 구분할 수 있다.**


![Caption](img/day04_1.jpg)


![Caption](img/day04_2.jpg)


![Caption](img/day04_3.jpg)


# 가능도 함수


![Caption](img/day04_4.jpg)


![Caption](img/day04_5.jpg)


![Caption](img/day04_6.jpg)


![Caption](img/day04_7.jpg)


# 로지스틱 회귀모형의 유의성 검정


![Caption](img/day04_8.jpg)


![Caption](img/day04_9.jpg)


![Caption](img/day04_10.jpg)


# 로지스틱 회귀계수의 유의성 검정


로지스틱 회귀모형이 유의하다고 판단되면 다음 단계로 회귀계수별 유의성 검정을 실시한다. 


- 로그 가능도 비를 이용한 방법
- z-검정 또는 Wald 검정


로그 가능도 비 검정으로 회귀계수의 유의성을 검정하는 방법은 간단하다. **만약 Mp 모형에 사용된 변수가 1개라면** 로그 가능도 비 검정으로 회귀모형의 유의성 검정은 물론 유일한 회귀계수의 검정도 가능하다.


![Caption](img/day04_11.jpg)


![Caption](img/day04_12.jpg)


# 이항 로지스틱 회귀분석 모형


![Caption](img/day04_13.jpg)


![Caption](img/day04_14.jpg)


![Caption](img/day04_15.jpg)


## 이항 로지스틱 회귀분석 실습


### 1. 로지스틱 회귀모형 적합하기 


```{r}
load(file = "practice_data/univ.RData")

# 구조 확인하기
str(univ)


# 10줄만 출력해보기
head(univ, n = 10)

# admit과 rank 펙터로 변환하기
univ$admit <- as.factor(univ$admit)
univ$rank <- as.factor(univ$rank)

# 구조 다시 확인하기
str(univ)

ggplot(data = univ) +
  geom_boxplot(mapping = aes(x = rank,
                             y = gre,
                             color = rank))

ggplot(data = univ) +
  geom_boxplot(mapping = aes(x = rank,
                             y = gpa,
                             color = rank))

# 요약 데이터 확인하기(이것도 잘 활용하자!)
summary(univ)

# 비율확인하기
univ$admit %>% table() %>% prop.table()
univ$rank %>% table() %>% prop.table()

# 합격자의 비중이 더 낮은 불균형 데이터이므로,
# ROSE 패키지의 ovun.sample() 함수로 표본 샘플링 후 모형을 적합하거나
# 매튜의 상관계수(MCC)를 사용하여 목표변수를 분류하면 된다.

set.seed(123)

index <- sample(x = 1:2,
                size = nrow(univ),
                prob = c(0.7,0.3),
                replace = TRUE)

trainset <- univ[index == 1, ]
testset <- univ[index == 2, ]

# 비율 확인하기
trainset$admit %>% table() %>% prop.table()
testset$admit %>% table() %>% prop.table()

# 이항 로지스틱 회귀모형 적합하기
fit.lr1 <- glm(formula = admit ~.,
               data = trainset,
               family = binomial(link = 'logit'))

summary(fit.lr1)
```


- rank라는 이름을 가진 더미변수 3개가 형성되었다.
- 모든 회귀계수의 p-value가 0.05보다 낮다.
- Null과 Residual deviance값이 추력된다.
- AIC값이 출력된다.
- Fisher Scoring iterations은 모델 적합에 소요된 횟수를 의미하지만 무시해도 된다.


### 2.1 회귀모형 유의성 검정 방법 1 : 카이제곱 통계량


```{r}
# 두 편차의 차이
dev.gap <- fit.lr1$null.deviance - fit.lr1$deviance
print(dev.gap)

# 두 모형의 자유도 차이
df.gap <- fit.lr1$df.null - fit.lr1$df.residual
print(df.gap)

# 카이제곱 검정 실행
pchisq(q = dev.gap, df = df.gap, lower.tail = FALSE)
```


유의확률이 0.05보다 작기 때문에 두 모형이 서로 같다고 할 수 없다. 최소한 1개 이상의 회귀계수가 0이 아님을 뜻한다.


### 2.2 회귀모형 유의성 검정 방법 2 : 로그 가능도 비


```{r}
# 입력변수가 사용되지 않은 로지스틱 회귀모형을 적합한다.
# 1을 입력하면 상수항만 적용한다는 뜻이 된다.
fit.lr0 <- glm(formula = admit ~ 1,
               data = trainset,
               family = binomial(link = "logit"))

summary(fit.lr0)

# 두 모형의 로그 가능도 비를 계산한다.
llr <-  -2*(logLik(fit.lr0) - logLik(fit.lr1))
print(llr)

# 카이제곱 검정을 실행한다.(결과는 동일하다)
pchisq(q = llr, df = df.gap, lower.tail = FALSE)


# lmtest 패키지를 사용하여 쉽게 가능도 비 검정하기
library(lmtest)
lrtest(fit.lr0, fit.lr1)

# lmtest 패키지의 waldtest() 함수는 상수항 모형을 적합할 필요가 없다.
# test인자는 생략가능하며, object2 인자에서 제외할 입력변수를 지정한다.
waldtest(object = fit.lr1, test = c("F","Chisq"))


waldtest(object = fit.lr1, object2 = c("gre","gpa"))
```


유의확률이 0.05보다 작으면 입력변수를 제외한 모형과 차이가 있다고 판단한다.


### 3. 회귀계수의 유의성 검정해보기


이미 summary()함수를 통하여 확인할 수 있지만, 3가지 방법으로 직접 유의성을 검정해보자.


```{r}
# 1. z-검정

# summary의 결과표 객체에 저장하기
coef.tbl <- fit.lr1 %>% summary() %>% `$`(coefficients) %>% as.data.frame()
colnames(coef.tbl) <- c("coef","se","z","pvalue")

coef.tbl

# z-stats는 회귀계수를 표준오차로 나눈 값이다.
coef.tbl$coef / coef.tbl$se

# z-stats의 누적확률 확인하기
pnorm(q = abs(coef.tbl$z), mean = 0, sd = 1, lower.tail = TRUE)

# 양측검정이므로, 1에서 누적확률을 빼고, 2를 곱하면 p-value이다.
(1- pnorm(q = abs(coef.tbl$z), mean = 0, sd = 1, lower.tail = TRUE))*2


# 2. Wald 검정
# 회귀계수와 표준오차를 각각 제곱한 다음 Wald 통계량을 계산한다.
wald.1 <- (coef.tbl$coef)^2 / (coef.tbl$se)^2
wald.1

# wald 통계량은 카이제곱 분포를 따르므로 카이제곱 검정을 실행한다.
# 이 때 자유도는 1이다.
# 참고로 lower.tail을 TRUE로 하면 1-pvalue 값이 나온다.
# pvalue를 구하는 것이 목적이므로, FALSE로 둔다.
pchisq(q = wald.1, df = 1, lower.tail = FALSE)


# 3. 회귀계수의 신뢰구간
# 회귀계수의 신뢰구간을 출력하여 양 끝점의 부호가 서로 같으면 해당 회귀계수는 0이 아니라고 할 수 있다.
confint(fit.lr1)
```


### 4. 회귀모형의 결과 해석
```{r}
# 각 입력변수의 오즈비 출력
fit.lr1 %>% coef() %>% exp()


# 더미변수 간 유의성 검정을 통해 차이가 있는지 확인하기
library(aod)

# sigma 인자 : 회귀계수의 분산-공분산 행렬을 할당한다.
# b 인자 : 회귀계수 벡터를 할당한다.
# Terms 인자 : 유의성 검정 대상인 회귀계수의 위치를 지정한다.
aod::wald.test(Sigma = vcov(fit.lr1),
               b = fit.lr1$coefficients,
               Terms = 4:6) %>% 
  `$`(result)


# Terms인자 대신 L 인자를 사용하면 더미변수의 회귀계수 간 차이를 확인할 수 있다.
# 비교하려는 회귀계수의 위치에 1과 -1을 지정하면 된다.
aod::wald.test(Sigma = vcov(fit.lr1),
               b = fit.lr1$coefficients,
               L = cbind(0,0,0,1,-1,0)) %>% 
  `$`(result)
```


y절편은 의미가 없으므로 제외하고 나머지 다섯 개의 회귀계수를 확인한다. 


**gre의 오즈비는 1이다.** 이는 곧, 다른 모든 조건이 같을 때 gre가 1단위 증가할 때마다 불합격할 확률 (1-p) 대비 합격할 확률(p)의 비율이 1배라는 뜻이다.결국 이는, **대학교 합격과 무관한 점수라고 볼 수 있다.**


반면에 gpa는 다섯 개의 회귀계수 중 대학교 합격에 가장 영향력 높은 입력변수이다.


더미변수 간 유의성 검정 결과가 유의확률이 0.05보다 작으면 더미변수 간 유의한 차이가 있다고 판단할 수 있다.


### 5. 회귀모형 성능 평가
```{r}
tr.prob <- fit.lr1$fitted.values
tr.pred <- ifelse(tr.prob >= 0.5, 1, 0) %>% as.factor()
tr.real <- trainset$admit

confusionMatrix(tr.pred, tr.real)
F1_Score(tr.real, tr.pred)
```


### 번외 : 메튜계수를 통하여 적합한 기준점 찾기(표본 샘플링을 하지 않았을 경우)
```{r}
tr.real %>% table() %>% prop.table()

plot(x = tr.real,
     y = tr.prob)

# 0.5를 기준점으로 하면, 대부분 불합격으로 분류된다. 따라서 불균형된 데이터셋으로 로지스틱 회귀모형을 적합하였다면 기준점은 0.5보다 아래로 내려야 한다.


# 0부터 1까지 0.01 단위로 총 101번 변경하면서 MCC를 계산한 뒤, MCC가 최대값을 갖는 기준점을 선택한다. 기준점이 여러 개라면, 가장 낮은 것을 택한다.


# MCC를 계산하는 사용자 정의 함수 생성
library(mccr)

get.mcc <- function(fit.model) {
  
  real <- fit.model$y %>% as.factor()
  cutoff <- seq(from = 0, to = 1, by = 0.01)
  
  df <- data.frame()
  
  for (i in cutoff) {
    
    pred <- ifelse(test = fit.model$fitted.values >= i, 1, 0) %>% as.factor()
    
    mcc <- mccr(act = real, pred = pred)
    df <- rbind(df, data.frame(cutoff = i, mcc = mcc))
    
  }
  
  return(df)

}

mcc.1 <- get.mcc(fit.lr1)
mcc.1

# 매튜의 상관계수가 최대값일 때 기준점을 확인한다.
mcc.1[mcc.1$mcc == max(mcc.1$mcc), "cutoff"]


# 새로운 기준점으로 성능지표를 확인한다.
tr.pred <- ifelse(fit.lr1$fitted.values >= 0.59, 1, 0) %>% as.factor()
tr.real <- trainset$admit

# 성능이 아주 미약하게 올랐다.
confusionMatrix(tr.pred, tr.real)
F1_Score(tr.real, tr.pred)
```


# 다항 로지스틱 회귀분석 모형


![Caption](img/day04_16.jpg)


자주 쓰이는 방법이 아니므로, 실습은 생략한다.